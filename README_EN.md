[ÁÆÄ‰Ωì‰∏≠Êñá](README.md) | English

<div align="center">
  <img src="docs/images/title.png" width = "400" />

A open-source digital human project

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![python version](https://img.shields.io/badge/python-3.7+-orange.svg)
![github stars](https://img.shields.io/github/stars/minivision-ai/MiniMeta.svg?style=flat)

</div>
<div align="center">
  <img src="docs/images/whole_body.gif" width = "400" />
</div>

## üî•Recent Updates
- `2022.04.29`: Initial commit.

## üìùIntroduction
**MiniMeta** It is an open-source digital human whole process project based on computer vision. **MiniMeta** contains face motion capture module [**MiniMeta-Face**](https://github.com/minivision-ai/MiniMeta-Face) , body motion capture module [**MiniMeta-Pose**](https://github.com/minivision-ai/MiniMeta-Pose) and human kinematics module [**MiniMeta-Kinematics**](https://github.com/minivision-ai/MiniMeta-Kinematics) . More features are continuously updated.

|Modules|Features|
|---|---|
|[MiniMeta-Face](https://github.com/minivision-ai/MiniMeta-Face) |Face detection, Face landmarks detection, Iris tracking, Head pose estimation, Blendshapes detection|
|[MiniMeta-Pose](https://github.com/minivision-ai/MiniMeta-Pose) |2D / 3D pose estimation, Joint rotations estimation, Human 3D position estimation|
|[MiniMeta-Kinematics](https://github.com/minivision-ai/MiniMeta-Kinematics) |Action estimation based on kinematics|

<div align="center">
  <img src="docs/images/pipeline.png" width = "600" />
</div>  

## üöÄStart

### Clone
```
git clone --recursive https://github.com/minivision-ai/MiniMeta.git
cd MiniMeta
```

### Download
[Google Drive](https://drive.google.com/file/d/1bJTglr6NaDlCA-YR1s1o_sCvTYJNmeqQ/view?usp=sharing) | [Baidu Cloud](https://pan.baidu.com/s/10dpwX76bP8JC76cp-DwjKA) (acess code: shae)

1. Unzip `resources` and put it into the `core/web_visualization` folder.
2. For the resources of each submodule in `modules`, please refer to the corresponding project download and configuration.

### Requirements
- Python 3.7+
- [three-py](https://github.com/panxinmiao/three-py)
- opencv
- onnxruntime or onnxruntime-gpu

```
conda create -n mimimeta python=3.7
conda activate mimimeta
pip install -r requirements.txt
```

Tip: The CPU version of onnxruntime is installed by default. If you need to use GPU to accelerate inference, please install onnxruntime-gpu and configure the corresponding CUDA environment.

### Test
1. Access camera and run:
```
python demo/meta_demo.py
```

2. Access page http://127.0.0.1:5000/MiniMeta.html in Chrome browser.

<div align="center">
  <img src="docs/images/upper_body.gif" width = "400" />
</div>

Welcome to join the technical communication QQ groupÔºö227192120
